{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"><b>NAIVE BAYES CLASSIFICATION</b></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is a classification algorithm based on Bayes' theorem with a strong assumption of independence between features. It is a simple yet effective algorithm widely used in text classification and spam filtering tasks. \n",
    "\n",
    "The Naive Bayes classifier calculates the probability of a given input belonging to a particular class by using Bayes' theorem. The theorem states that the probability of a hypothesis (class) being true, given the observed evidence (features), is proportional to the likelihood of the evidence given the hypothesis, multiplied by the prior probability of the hypothesis. In the case of Naive Bayes, the assumption of independence allows us to simplify the calculation of the likelihood.\n",
    "\n",
    "### **1. PROBABILITY**\n",
    "#### **INDEPENDENT EVENT:**\n",
    "\n",
    "Independent events are events that have no influence on each other. In probability theory, two events are considered independent if the occurrence of one event does not affect the probability of the other event occurring.\n",
    "\n",
    "Mathematically, for two events A and B to be independent, the probability of their joint occurrence (A and B happening together) should be equal to the product of their individual probabilities. In other words, if $P(A)$ represents the probability of event A happening and $P(B)$ represents the probability of event B happening, then:\n",
    "\n",
    "$P(A and B) = P(A) * P(B)$\n",
    "\n",
    "This equation shows that the probability of both events happening together is simply the product of their individual probabilities.\n",
    "\n",
    "To determine whether events are independent, you can also check if the conditional probability of one event given the occurrence of the other event is equal to the probability of the first event. In other words:\n",
    "\n",
    "$P(A | B) = P(A)$\n",
    "\n",
    "If the above equation holds, it implies that the occurrence of event B has no impact on the probability of event A.\n",
    "\n",
    "It's important to note that independence of events is different from mutually exclusive events. Mutually exclusive events cannot occur together, whereas independent events can occur simultaneously without influencing each other.\n",
    "\n",
    "\n",
    "*Example:*\n",
    "1. Consider flipping a fair coin twice. Let's define two events:\n",
    "- Event A: The first coin flip results in a heads.\n",
    "- Event B: The second coin flip results in a heads.\n",
    "\n",
    "In this scenario, Event A and Event B are independent events because the outcome of the first coin flip does not affect the outcome of the second coin flip.\n",
    "\n",
    "The probability of getting a heads on a fair coin is 0.5. So, the probability of Event A (getting heads on the first coin flip) is $P(A) = 0.5$.\n",
    "\n",
    "Similarly, the probability of getting heads on the second coin flip is also 0.5. So, the probability of Event B (getting heads on the second coin flip) is $P(B) = 0.5.$\n",
    "\n",
    "Now, let's calculate the joint probability of both events occurring together. Since the coin flips are independent, the joint probability can be calculated as the product of their individual probabilities:\n",
    "\n",
    "$P(A and B) = P(A) * P(B) = 0.5 * 0.5 = 0.25$\n",
    "\n",
    "So, the probability of both coin flips resulting in heads is 0.25.\n",
    "\n",
    "In this example, the independence of the events is evident as the outcome of the first coin flip does not affect the outcome of the second coin flip.\n",
    "\n",
    "2. Rolling a Dice.\n",
    "\n",
    "#### **DEPENDENT EVENT:**\n",
    "\n",
    "In probability theory, dependent events are events that are influenced by or affected by the occurrence of other events. In other words, the outcome or probability of one event is influenced by the outcome or occurrence of another event.\n",
    "\n",
    "There are two types of dependence between events: dependent and independent.\n",
    "\n",
    "1. Independent Events: Independent events are those in which the occurrence or outcome of one event has no influence on the occurrence or outcome of another event. In this case, the probability of one event happening does not affect the probability of the other event happening. For example, when flipping a fair coin twice, the outcome of the first flip (heads or tails) does not affect the outcome of the second flip.\n",
    "\n",
    "2. Dependent Events: Dependent events are events where the outcome or occurrence of one event affects the outcome or occurrence of another event. The probability of one event happening is influenced by the outcome of the other event. For example, drawing cards from a deck without replacement is an example of dependent events. The probability of drawing a certain card in the second draw depends on the outcome of the first draw because the deck has changed.\n",
    "\n",
    "To determine the probability of dependent events, you need to consider the information from previous events. You can use conditional probability, which is the probability of an event given that another event has already occurred.\n",
    "\n",
    "When calculating the probability of dependent events, you often use the multiplication rule. The multiplication rule states that the probability of two dependent events A and B occurring is equal to the probability of event A happening multiplied by the probability of event B happening given that event A has occurred. Mathematically, it can be written as \n",
    "$P(A and B) = P(A) * P(B|A).$\n",
    "\n",
    "Understanding the dependence between events is important in various fields, including statistics, probability theory, and decision-making. It helps in analyzing real-life situations, making predictions, and understanding the relationships between different events.\n",
    "\n",
    "*Example:*\n",
    "\n",
    "Suppose you have a bag containing 5 red marbles and 3 blue marbles. You randomly select two marbles from the bag without replacement. Let's consider the following events:\n",
    "\n",
    "Event A: Selecting a red marble on the first draw.\n",
    "Event B: Selecting a blue marble on the second draw.\n",
    "\n",
    "In this scenario, the events are dependent because the outcome of the first draw affects the outcome of the second draw. Let's calculate the probabilities:\n",
    "\n",
    "The probability of event A (selecting a red marble on the first draw) is P(A) = 5/8 because there are 5 red marbles out of a total of 8 marbles in the bag.\n",
    "\n",
    "After the first draw, we have 4 red marbles and 3 blue marbles remaining in the bag. So, for event B (selecting a blue marble on the second draw), the probability P(B|A) is 3/7 because there are 3 blue marbles left out of a total of 7 marbles remaining.\n",
    "\n",
    "Using the multiplication rule, we can calculate the probability of both events occurring:\n",
    "\n",
    "$P(A and B) = P(A) * P(B|A)$\n",
    "           = $(5/8) * (3/7)$\n",
    "           ≈ $0.2679$\n",
    "\n",
    "So, the probability of selecting a red marble on the first draw and a blue marble on the second draw, without replacement, is approximately 0.2679 or 26.79%.\n",
    "\n",
    "### **2. BAYES THEOREM:**\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It provides a way to update the probability of a hypothesis (an event or proposition) based on new evidence or observed data. The theorem is named after Thomas Bayes, an 18th-century English mathematician.\n",
    "\n",
    "Mathematically, Bayes' theorem can be stated as follows:\n",
    "\n",
    "$P(A|B) = (P(B|A) * P(A)) / P(B)$\n",
    "\n",
    "Where:\n",
    "- P(A|B) is the posterior probability of hypothesis A given the evidence B.\n",
    "- P(B|A) is the likelihood, or the probability of observing the evidence B given that hypothesis A is true.\n",
    "- P(A) is the prior probability of hypothesis A, i.e., the probability of A being true before considering any evidence.\n",
    "- P(B) is the probability of observing the evidence B, regardless of the hypothesis.\n",
    "\n",
    "The theorem allows us to update our beliefs or probabilities about a hypothesis based on new evidence. Here's a step-by-step explanation of how Bayes' theorem is applied:\n",
    "\n",
    "1. Establish the prior probability: Start with an initial estimate or belief about the probability of the hypothesis A before considering any evidence, denoted by $P(A)$.\n",
    "\n",
    "2. Determine the likelihood: Assess the likelihood of observing the evidence B given that hypothesis A is true, denoted by $P(B|A)$. This represents how well the evidence supports the hypothesis.\n",
    "\n",
    "3. Calculate the marginal likelihood: Determine the probability of observing the evidence B, regardless of the hypothesis, denoted by $P(B)$. This is calculated by considering the total probability of all possible ways in which B can occur.\n",
    "\n",
    "4. Compute the posterior probability: Apply Bayes' theorem to calculate the updated probability of the hypothesis A given the evidence B, denoted by $P(A|B)$. This is done by multiplying the prior probability by the likelihood and dividing by the marginal likelihood.\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, data analysis, and decision-making. It provides a formal framework for updating beliefs and making rational inferences based on observed data or evidence. The theorem has numerous applications, such as spam filtering, medical diagnosis, natural language processing, and Bayesian inference in statistics.\n",
    "\n",
    "\n",
    "In this example, the occurrence of event A (selecting a red marble) affects the probability of event B (selecting a blue marble) because the number of available red and blue marbles changes after the first draw.\n",
    "\n",
    "\n",
    "#### **CONDITIONAL PROBABILITY:**\n",
    "\n",
    "Conditional probability is a concept in probability theory that measures the probability of an event occurring given that another event has already occurred. It allows us to calculate the probability of an event A happening, given that event B has occurred.\n",
    "\n",
    "The conditional probability of event A given event B is denoted as P(A|B), read as \"the probability of A given B\". It can be calculated using the formula:\n",
    "\n",
    "$P(A|B) = P(A ∩ B) / P(B)$\n",
    "\n",
    "Where:\n",
    "- $P(A ∩ B)$ represents the probability of both events A and B occurring simultaneously, i.e., the intersection of A and B.\n",
    "- $P(B)$ is the probability of event B occurring.\n",
    "\n",
    "To calculate the conditional probability, we divide the probability of the joint occurrence of events A and B by the probability of event B alone. This normalization accounts for the fact that we are considering event B as the new sample space.\n",
    "\n",
    "It's important to note that the conditional probability is only defined when P(B) is not equal to zero, i.e., when event B has a non-zero probability of occurring.\n",
    "\n",
    "Here's an example to illustrate conditional probability:\n",
    "\n",
    "Suppose you have a deck of 52 cards, and you draw one card at random. Let's define the following events:\n",
    "- A: Drawing a heart card.\n",
    "- B: Drawing a red card.\n",
    "\n",
    "Now, we want to calculate the probability of drawing a heart card given that we have already drawn a red card (event B).\n",
    "\n",
    "The probability of drawing a red card (B) is $P(B) = 26/52 = 1/2$, since half of the cards in the deck are red.\n",
    "\n",
    "The probability of drawing a heart card and a red card simultaneously $(A ∩ B) is P(A ∩ B) = 13/52 = 1/4$, as there are 13 red hearts in the deck.\n",
    "\n",
    "Using the formula for conditional probability, we have:\n",
    "$P(A|B) = P(A ∩ B) / P(B) = (1/4) / (1/2) = 1/2$\n",
    "\n",
    "Therefore, the probability of drawing a heart card given that we have already drawn a red card is 1/2.\n",
    "\n",
    "Conditional probability plays a crucial role in various fields, including statistics, machine learning, and decision-making, as it allows us to update probabilities based on new information or events that have occurred.\n",
    "\n",
    "\n",
    "#### **CUMULATIVE PROBABILITY:**\n",
    "\n",
    "Cumulative probability, also known as cumulative distribution function (CDF), refers to the probability that a random variable takes on a value less than or equal to a given value. In other words, it measures the probability of a random variable being less than or equal to a specific value.\n",
    "\n",
    "The cumulative probability is denoted as $P(X ≤ x)$, where X is the random variable and x is the value for which we want to calculate the cumulative probability. The cumulative probability function gives the probability of the random variable being less than or equal to a particular value.\n",
    "\n",
    "Mathematically, the cumulative probability function can be defined as:\n",
    "\n",
    "$F(x) = P(X ≤ x)$\n",
    "\n",
    "The cumulative probability function satisfies the following properties:\n",
    "\n",
    "1. The cumulative probability is always between 0 and 1: 0 ≤ F(x) ≤ 1.\n",
    "2. The cumulative probability is a non-decreasing function: If x1 < x2, then F(x1) ≤ F(x2).\n",
    "3. The cumulative probability approaches 1 as x approaches positive infinity: lim(x→∞) F(x) = 1.\n",
    "4. The cumulative probability approaches 0 as x approaches negative infinity: lim(x→-∞) F(x) = 0.\n",
    "\n",
    "The cumulative probability function provides a complete description of the probability distribution of a random variable. By evaluating the cumulative probability function at different values of x, we can determine the probabilities associated with various ranges of values or calculate percentiles.\n",
    "\n",
    "It's worth noting that the cumulative probability function is closely related to the probability density function (PDF) for continuous random variables. The PDF gives the probability density at a specific value, while the cumulative probability function integrates the PDF from negative infinity up to that value, yielding the cumulative probability.\n",
    "\n",
    "Cumulative probability is widely used in statistics, probability theory, and data analysis. It helps in understanding the overall distribution of a random variable and allows for the calculation of various statistics and quantiles associated with the distribution.\n",
    "\n",
    "**Here's a step-by-step overview of how the Naive Bayes algorithm works:**\n",
    "\n",
    "1. Data Preparation: First, you need to prepare your training data by representing each instance with a set of features or attributes. These features can be categorical or numerical.\n",
    "\n",
    "2. Training: The Naive Bayes algorithm calculates the probabilities of each feature given each class in the training dataset. It estimates the prior probability of each class by counting the frequency of each class in the training data.\n",
    "\n",
    "3. Feature Independence Assumption: Naive Bayes assumes that all features are independent of each other given the class label. Although this assumption is rarely true in real-world scenarios, Naive Bayes can still perform well in many cases.\n",
    "\n",
    "4. Likelihood Calculation: Naive Bayes calculates the likelihood of each feature given the class using the training data. For categorical features, it estimates the probability by counting the frequency of each feature value for each class. For numerical features, it typically assumes a probability distribution (e.g., Gaussian distribution) and estimates the mean and standard deviation for each class.\n",
    "\n",
    "5. Applying Bayes' Theorem: Once the likelihoods and priors are calculated, Naive Bayes applies Bayes' theorem to calculate the posterior probability of each class given the observed features. The class with the highest posterior probability is then assigned as the predicted class.\n",
    "\n",
    "6. Classification: Finally, the trained Naive Bayes model can be used to classify new, unseen instances by applying the same calculations to calculate the posterior probabilities and selecting the most probable class.\n",
    "\n",
    "One of the main advantages of Naive Bayes is its simplicity and efficiency. It can handle large feature spaces and is particularly effective when the independence assumption holds reasonably well. However, its performance may suffer if the features are highly dependent or if there is insufficient training data. Additionally, Naive Bayes is not suitable for tasks that require capturing complex relationships between features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. A Person Played Tennis or Not at Different Condition?**\n",
    "\n",
    "<center>\n",
    "\n",
    "| DAY | <div style=\"text-align: center;\">OUTLOOK</div> | <div style=\"text-align:center;\">TEMPERATURE</div> | <div style=\"text-align:center;\">HUMIDITY</div> | <div style=\"text-align:center;\">WIND</div> | <div style=\"text-align:center;\">PLAY TENNIS</div> |\n",
    "|-----|---------|-------------|----------|------|-------------|\n",
    "| D1  | Sunny   | Hot         | High     | Weak | No          |\n",
    "| D2  | Sunny   | Hot         | High     | Strong| No         |\n",
    "| D3  | Overcast| Hot         | High     | Weak | Yes         |\n",
    "| D4  | Rainy   | Mild        | High     | Weak | Yes         |\n",
    "| D5  | Rainy   | Cool         | Normal     | Weak | Yes          |\n",
    "| D6  | Rainy   | Cool         | Normal     | Strong | No          |\n",
    "| D7  | Overcast| Cool         | Normal     | Strong | Yes          |\n",
    "| D8  | Sunny   | Mild         | High     | Weak | No          |\n",
    "| D9  | Sunny   | Cool         | Normal     | Weak | Yes          |\n",
    "| D10 | Rainy   | Mild         | Normal     | Weak | Yes          |\n",
    "| D11 | Sunny   | Mild         | Normal     | Strong | Yes          |\n",
    "| D12 | Overcast| Mild         | High     | Strong | Yes          |\n",
    "| D13 | Overcast| Hot         | Normal     | Weak | Yes          |\n",
    "| D14 | Rainy   | Mild         | High     | Strong | No          |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OUTLOOK FEATURE**\n",
    "- There are 3 unique categories in `OUTLOOK` Feature. i.e. Sunny, Overcast, Rainy.\n",
    "\n",
    "<center>\n",
    "\n",
    "| CATEGORY | YES | NO | PR(E/YES) | PR(E/NO) |\n",
    "|----------|-----|----|-----------|----------|\n",
    "| Sunny    | 2   | 3  | 2/9       | 3/5      |\n",
    "| Overcast | 4   | 0  | 4/9       | 0/5      |\n",
    "| Rain     | 3   | 2  | 3/9       | 2/5      |\n",
    "|<b>Total</b>     | 9   | 5  |           |          |\n",
    "</CENTER>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEMPERATURE FEATURE**\n",
    "- There are 3 unique categories in `TEMPERATURE` Feature. i.e. Hot, Mild, Cool.\n",
    "\n",
    "<center>\n",
    "\n",
    "| CATEGORY | YES | NO | PR(E/YES) | PR(E/NO) |\n",
    "|----------|-----|----|-----------|----------|\n",
    "| Hot    | 2   | 2  | 2/9       | 2/5      |\n",
    "| Mild | 4   | 2  | 4/9       | 2/5      |\n",
    "| Cool     | 3   | 1  | 3/9       | 1/5      |\n",
    "|<b>Total</b>     | 9   | 5  |           |          |\n",
    "</CENTER>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Yes = 9\n",
    "\n",
    "Total No = 5\n",
    "\n",
    "$Pr(Yes) = 9/14$\n",
    "\n",
    "$Pr(No) = 5/14$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Pr(Yes/(Sunny, Hot))$ = $Pr(Yes) * Pr(Sunny/Yes) * Pr(Hot/Yes)$\n",
    "\n",
    "                       = (9/14) * (2/9) * (2/9)\n",
    "\n",
    "                       = 2/63\n",
    "\n",
    "$Pr(Yes/(Sunny, Hot))$ = $0.031$\n",
    "\n",
    "\n",
    "$Pr(No/(Sunny, Hot))$ = $Pr(No) * Pr(Sunny/No) * Pr(Hot/No)$\n",
    "\n",
    "                       = (5/14) * (3/5) * (2/5)\n",
    "\n",
    "                       \n",
    "$Pr(No/(Sunny, Hot))$ = $0.085$\n",
    "\n",
    "\n",
    "$Pr(Yes/(Sunny, Hot)) = (0.031)/(0.031 + 0.085) = 0.27 = 27% $\n",
    "\n",
    "$Pr(No/(Sunny, Hot)) = (0.085)/(0.031 + 0.085) = 0.7327 = 73.27% $\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. FIND OUT PROBABILITY OF OUTLOOK - RAINY AND TEMPERATURE - MILD?**\n",
    "\n",
    "$Pr(Yes/(Rainy, Mild)$ = $Pr(Yes) * Pr(Rainy/Yes) * Pr(Mild/Yes)$\n",
    "\n",
    "                       = (9/14) * (3/9) * (4/9)\n",
    "                       \n",
    "$Pr(Yes/(Rainy, Mild))$ = $0.095$\n",
    "\n",
    "\n",
    "$Pr(No/(Rainy, Mild))$ = $Pr(No) * Pr(Rainy/No) * Pr(Mild/No)$\n",
    "\n",
    "                       = (5/14) * (2/5) * (2/5)\n",
    "\n",
    "                       \n",
    "$Pr(No/(Rainy, Mild))$ = $0.0571$\n",
    "\n",
    "\n",
    "$Pr(Yes/(Rainy, Mild)) = (0.095) / (0.095 + 0.0571) = .6244 = 62.44$\n",
    "\n",
    "$Pr(No/(Rainy, Mild)) = (0.0571) / (0.095 + 0.0571) = .3754 = 37.54$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **TYPES OF NAIVE BAYES**\n",
    "\n",
    "#### **1. Bernoulli Naive Bayes:**\n",
    "- **BernoulliNB** implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable. Therefore, this class requires samples to be represented as binary-valued feature vectors; if handed any other kind of data, a BernoulliNB instance may binarize its input (depending on the binarize parameter).\n",
    "\n",
    "\n",
    "#### **2. Multinomial Naive Bayes:**\n",
    "- **MultinomialNB** implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Gaussian Naive Bayes:**\n",
    "- Whenever Your Independent Features Follows Gaussian Distribution then We Will use Gaussian Naive Bayes.\n",
    "- Independent Features ==> Follows Gaussian Naive Bayes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb =  GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_g = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Mislabeled Points Out of a Total 45 Points: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Mislabeled Points Out of a Total {X_test.shape[0]} Points: {(y_test != y_pred_g).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.78"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred_g)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
