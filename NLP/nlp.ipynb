{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"><b>NATURAL LANGUAGES PROCESSING(NLP)</b></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples of NLP Projects:**\n",
    "\n",
    "1. Chatbots\n",
    "\n",
    "2. Alexa, siri, Google Asst., cortana,--- we will talk to them.\n",
    "\n",
    "3. Sentiment Analysis-- Twitter tiwts, movie reviews, etc.\n",
    "    \n",
    "4. Email AI Tools.\n",
    "\n",
    "5. Translator English to Marathi\n",
    "\n",
    "\n",
    "In NLP We will use Machine Learning & Deep Learning Models\n",
    "\n",
    "- Input in the form of Text.\n",
    "\n",
    "- Output in the form of Classification i.e. 0 or 1\n",
    "\n",
    "$y = f(x)$\n",
    "\n",
    "$y$ -- Output\n",
    "$x$ -- Input(Text)\n",
    "$f()$ -- Machine Learning Model\n",
    "\n",
    "- Most Important task is convert input data text into numeric data.\n",
    "\n",
    "- NLP\n",
    "\n",
    "Data[Text] -------> Data[Numerica] --------> Machine Learning------> y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP (Natural Language Processing) is a field of study that focuses on the interaction between computers and human language. It involves several steps or processes to understand and generate human language. Here are the typical steps involved in NLP:\n",
    "\n",
    "1. Text Preprocessing: The first step is to preprocess the text data to clean and normalize it. This includes tasks such as removing special characters, converting text to lowercase, tokenization (splitting text into individual words or tokens), and removing stop words (common words like \"the,\" \"is,\" etc. that do not carry much meaning).\n",
    "\n",
    "2. Morphological Analysis: In this step, the words are further analyzed to determine their base or root form. This involves tasks like stemming (reducing words to their base form by removing prefixes and suffixes) and lemmatization (reducing words to their dictionary form or lemma).\n",
    "\n",
    "3. Part-of-Speech (POS) Tagging: POS tagging involves assigning grammatical tags to each word in a sentence, such as noun, verb, adjective, etc. This step helps in understanding the syntactic structure of the sentence.\n",
    "\n",
    "4. Named Entity Recognition (NER): NER aims to identify and classify named entities in the text, such as names of persons, organizations, locations, dates, etc. This step is crucial for information extraction and understanding the context of the text.\n",
    "\n",
    "5. Parsing: Parsing involves analyzing the grammatical structure of a sentence to understand the relationships between words. It helps in creating a parse tree that represents the syntactic structure of the sentence.\n",
    "\n",
    "6. Sentiment Analysis: Sentiment analysis determines the sentiment or opinion expressed in a piece of text. It can be classified into positive, negative, or neutral. This step is useful in understanding the sentiment of customers in reviews, social media posts, etc.\n",
    "\n",
    "7. Text Classification: Text classification involves categorizing a piece of text into predefined classes or categories. It is often used for tasks like spam detection, sentiment analysis, topic classification, etc.\n",
    "\n",
    "8. Machine Translation: Machine translation involves automatically translating text from one language to another. This is a complex task that requires techniques such as statistical machine translation or neural machine translation.\n",
    "\n",
    "9. Question Answering: Question answering systems aim to automatically answer questions based on a given context or knowledge base. It involves understanding the question, searching for relevant information, and generating an appropriate answer.\n",
    "\n",
    "10. Text Generation: Text generation focuses on generating human-like text based on a given prompt or context. It can be used for tasks like chatbots, language translation, text summarization, and story generation.\n",
    "\n",
    "These steps are not always performed sequentially and can vary depending on the specific NLP task or application. Additionally, the advancements in deep learning and neural networks have led to the development of end-to-end NLP models that can perform multiple tasks simultaneously without explicit step-wise processing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text preprocessing**\n",
    "\n",
    " is an important step in NLP that involves cleaning and preparing the text data before further analysis or modeling. Here are the common text preprocessing steps:\n",
    "\n",
    "1. Removing special characters and punctuation: Special characters, such as hashtags, mentions, URLs, or any non-alphanumeric characters, are often removed as they do not contribute much to the overall meaning of the text. Punctuation marks like commas, periods, and quotation marks are also typically removed.\n",
    "\n",
    "2. Converting text to lowercase: Converting all text to lowercase helps in standardizing the text and treating words with different capitalizations as the same word. This step reduces the vocabulary size and avoids duplication of words.\n",
    "\n",
    "3. Tokenization: Tokenization involves splitting the text into individual words or tokens. This step is essential for further analysis, as it breaks down the text into manageable units. Tokenization can be performed at the word level or the character level.\n",
    "\n",
    "4. Removing stop words: Stop words are common words that do not carry much meaning and occur frequently in the text, such as \"the,\" \"is,\" \"and,\" etc. Removing stop words helps reduce noise in the data and focuses on more meaningful words.\n",
    "\n",
    "5. Handling contractions: Contractions like \"don't,\" \"can't,\" \"won't,\" etc., are often expanded to their full forms (\"do not,\" \"cannot,\" \"will not\") to maintain consistency and avoid ambiguity in the text.\n",
    "\n",
    "6. Removing numbers: If numerical values are not relevant to the analysis or modeling task, they can be removed from the text. However, if numbers carry significance (e.g., in sentiment analysis of product reviews), they may be retained.\n",
    "\n",
    "7. Spell correction: Text data may contain spelling errors or typos. Applying spell correction techniques can help standardize the text and improve accuracy during analysis. This can involve techniques like using a pre-built dictionary or employing algorithms like Levenshtein distance or edit distance.\n",
    "\n",
    "8. Lemmatization or stemming: Lemmatization and stemming aim to reduce words to their base or root form. Lemmatization considers the context of the word and converts it to its dictionary form, while stemming applies rules to strip off prefixes or suffixes to obtain the base form. These techniques help in reducing word variations and improving text analysis.\n",
    "\n",
    "9. Removing or handling irrelevant information: In some cases, there may be specific patterns or information in the text that are not relevant to the analysis or modeling task. These could include HTML tags, XML tags, or specific domain-specific information. Removing or handling such irrelevant information is important for data cleanliness.\n",
    "\n",
    "These preprocessing steps may vary depending on the specific task or requirements. It's important to choose the preprocessing steps that align with the objectives of the NLP task and the characteristics of the text data being processed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Tokenization:**\n",
    "\n",
    "Tokenization is the process of dividing a sequence of text into smaller units called tokens. In NLP, tokens can be words, sentences, or subword units, depending on the granularity of the analysis required. Tokenization is a fundamental step in various NLP tasks, such as text classification, machine translation, sentiment analysis, and information retrieval.\n",
    "\n",
    "Here are some commonly used tokenization techniques:\n",
    "\n",
    "1. Word Tokenization: This technique splits the text into individual words. The basic approach is to split the text wherever a space or whitespace occurs. However, it can be more complex when dealing with languages that don't use spaces between words, or when handling contractions, hyphenated words, or punctuation marks. Tokenizing at the word level is a common choice for many NLP tasks.\n",
    "\n",
    "Example: \"I love natural language processing.\" -> [\"I\", \"love\", \"natural\", \"language\", \"processing\"]\n",
    "\n",
    "2. Sentence Tokenization: Sentence tokenization divides the text into individual sentences. This is particularly useful when the analysis requires understanding the context at the sentence level.\n",
    "\n",
    "Example: \"I love natural language processing. It is fascinating.\" -> [\"I love natural language processing.\", \"It is fascinating.\"]\n",
    "\n",
    "3. Subword Tokenization: Subword tokenization splits the text into smaller units that are not necessarily complete words. This technique is often used when dealing with morphologically rich languages, rare words, or to handle out-of-vocabulary (OOV) words. It helps capture meaningful subword units and improves the generalization of models.\n",
    "\n",
    "Example: \"Unhappiness\" -> [\"Un\", \"happi\", \"ness\"]\n",
    "\n",
    "4. Custom Tokenization: Depending on the specific requirements of the task, you can develop custom tokenization techniques. This could involve regular expressions, rule-based approaches, or specific domain knowledge to split the text into meaningful units.\n",
    "\n",
    "Tokenization plays a crucial role in preparing text data for further analysis or modeling. Once the text is divided into tokens, it becomes more manageable for subsequent NLP tasks like feature extraction, part-of-speech tagging, named entity recognition, and syntactic parsing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Stopwords:**\n",
    "\n",
    "Stopwords are common words that occur frequently in a language and often do not carry much semantic meaning or contribute significantly to the overall understanding of a text. Examples of stopwords in English include words like \"the,\" \"is,\" \"and,\" \"a,\" \"an,\" etc.\n",
    "\n",
    "In NLP, it is common to remove stopwords from text data during the preprocessing stage. Here are a few reasons why stopwords are removed:\n",
    "\n",
    "1. Noise reduction: Stopwords are highly frequent and occur in almost every text. By removing stopwords, we can reduce the noise in the data and focus on the more meaningful words that convey important information.\n",
    "\n",
    "2. Memory and storage efficiency: Removing stopwords helps reduce the vocabulary size and the memory or storage required to store the text data. This can be particularly beneficial when working with large datasets or when memory resources are limited.\n",
    "\n",
    "3. Computational efficiency: Stopword removal can speed up subsequent NLP tasks, such as text classification or information retrieval, as there are fewer words to process. It reduces the processing time and improves the overall efficiency of the system.\n",
    "\n",
    "4. Improved analysis accuracy: Stopwords often do not provide much discriminatory power and can dilute the significance of other important words in the text. Removing them can improve the accuracy of certain NLP tasks, such as sentiment analysis or text categorization.\n",
    "\n",
    "However, it's important to note that the decision to remove stopwords depends on the specific task and the characteristics of the text data. In some cases, such as language modeling or certain information retrieval tasks, keeping stopwords may be necessary to maintain the integrity of the text or preserve the original context.\n",
    "\n",
    "The choice of stopwords can also vary depending on the language and the specific domain or application. Common stopwords lists are available for different languages, but it's important to review and customize them based on the specific requirements of the task and the characteristics of the text data being processed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Stemming:**\n",
    "\n",
    "Stemming is a process in natural language processing (NLP) that aims to reduce words to their base or root form, known as a stem. The stem may not always be a complete word but captures the core meaning or essence of the word. The purpose of stemming is to reduce the inflectional forms or variations of words to a common base form, which can help improve text analysis and information retrieval.\n",
    "\n",
    "Here's an example to illustrate the process of stemming using the Porter stemming algorithm, a popular stemming algorithm:\n",
    "\n",
    "Original words:\n",
    "- Running\n",
    "- Runs\n",
    "- Runner\n",
    "- Ran\n",
    "\n",
    "Stemmed words:\n",
    "- Run\n",
    "- Run\n",
    "- Runner\n",
    "- Ran\n",
    "\n",
    "In this example, stemming reduces different variations of the word \"run\" to its base form \"run.\" The stemmed words can be treated as the same word, which can help in tasks such as text classification, information retrieval, and document clustering.\n",
    "\n",
    "Stemming algorithms often use heuristic rules and patterns to strip off common prefixes and suffixes from words. They do not consider the context or semantics of the word but focus on reducing word variations based on linguistic rules.\n",
    "\n",
    "It's important to note that stemming may not always produce a dictionary word, and there may be cases where the stemmed word loses its original meaning or becomes ambiguous. Therefore, the choice of stemming depends on the specific task and the trade-off between simplicity and accuracy in the given context.\n",
    "\n",
    "Popular stemming algorithms include the Porter stemming algorithm, Snowball stemming algorithm (an extension of Porter stemming), and the Lancaster stemming algorithm. These algorithms have implementations available in various programming languages and NLP libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Lemmatization:**\n",
    "\n",
    "Lemmatization, similar to stemming, is a process in natural language processing (NLP) that aims to reduce words to their base or dictionary form called a lemma. However, unlike stemming, lemmatization considers the context and part of speech (POS) of the word to derive its lemma, which ensures that the resulting lemma is a valid word in the language.\n",
    "\n",
    "Here's an example to illustrate the process of lemmatization using the WordNet lemmatizer, a commonly used lemmatization tool:\n",
    "\n",
    "Original words:\n",
    "- Running\n",
    "- Runs\n",
    "- Runner\n",
    "- Ran\n",
    "\n",
    "Lemmatized words:\n",
    "- Run\n",
    "- Run\n",
    "- Runner\n",
    "- Run\n",
    "\n",
    "In this example, lemmatization reduces different inflectional forms of the word \"run\" to its base form \"run\" while preserving the grammatical category of the word. This can be useful in maintaining the semantic meaning of words and improving the accuracy of downstream NLP tasks.\n",
    "\n",
    "Lemmatization typically involves the use of linguistic resources like dictionaries or morphological analysis to map words to their lemmas. It takes into account factors such as word morphology, POS, and sometimes the context in which the word appears to accurately derive the lemma.\n",
    "\n",
    "It's important to note that lemmatization is generally more computationally expensive compared to stemming, as it requires access to lexical resources and performs more complex analysis. However, the resulting lemmas tend to be linguistically more accurate and useful for tasks that require a deeper understanding of the text.\n",
    "\n",
    "Popular lemmatization libraries and tools include NLTK (Natural Language Toolkit), spaCy, and Stanford CoreNLP, which provide lemmatization capabilities for various programming languages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming and lemmatization Difference**\n",
    "\n",
    "Stemming and lemmatization are both techniques used in natural language processing (NLP) to reduce words to their base or root forms. However, there are some key differences between the two approaches:\n",
    "\n",
    "1. Output: Stemming typically produces a root form called a stem, which may not always be a valid word in the language. On the other hand, lemmatization produces a valid word in the language, known as a lemma.\n",
    "\n",
    "Example:\n",
    "- Stemming: Running -> Run\n",
    "- Lemmatization: Running -> Run\n",
    "\n",
    "2. Context and POS: Stemming algorithms do not consider the context or part of speech (POS) of the word. They apply simple heuristics and rules to strip off prefixes and suffixes. In contrast, lemmatization takes into account the word's POS and the context in which it appears to derive the lemma. This helps ensure that the lemma accurately represents the intended meaning of the word.\n",
    "\n",
    "Example:\n",
    "- Stemming: Saw (verb) -> Saw (noun)\n",
    "- Lemmatization: Saw (verb) -> See\n",
    "\n",
    "3. Language: Stemming algorithms are generally language-specific and rely on rules or patterns specific to that language. Lemmatization, on the other hand, often requires linguistic resources like dictionaries or morphological analysis that are built for specific languages.\n",
    "\n",
    "4. Accuracy: Stemming is a simpler and faster process compared to lemmatization but may result in overstemming or understemming. Overstemming refers to situations where different words are reduced to the same stem, losing their distinct meanings. Understemming occurs when words that should have the same stem are not reduced to the same form. Lemmatization, being more linguistically informed, tends to produce more accurate and meaningful results.\n",
    "\n",
    "5. Use Cases: Stemming is often used in information retrieval systems, search engines, and applications where speed and efficiency are crucial. Lemmatization is more suitable for tasks that require a deeper understanding of the language, such as text analysis, machine translation, sentiment analysis, and question-answering systems.\n",
    "\n",
    "Ultimately, the choice between stemming and lemmatization depends on the specific requirements of the NLP task, the language being processed, and the trade-off between simplicity and linguistic accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
