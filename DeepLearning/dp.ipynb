{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style:align='center'><b>DEEP LEARNING</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is a subfield of machine learning that focuses on training artificial neural networks to learn and make predictions or decisions based on input data. It is inspired by the structure and function of the human brain and is designed to simulate the learning process of neurons.\n",
    "\n",
    "In traditional machine learning approaches, engineers and data scientists manually design features and algorithms to solve specific tasks. However, deep learning automates this feature engineering process by allowing the model to learn hierarchical representations of the data directly from raw input. This is achieved by using artificial neural networks with multiple layers, hence the term \"deep\" learning.\n",
    "\n",
    "Deep learning models are composed of interconnected nodes called artificial neurons or \"units.\" These units are organized into layers, where each layer receives input from the previous layer and passes its output to the next layer. The layers are typically divided into an input layer, one or more hidden layers, and an output layer. The hidden layers are responsible for learning complex representations of the data, while the output layer produces the final prediction or decision.\n",
    "\n",
    "During the training process, deep learning models are exposed to labeled data, and the weights and biases of the connections between units are adjusted iteratively to minimize the difference between the predicted output and the true output. This optimization process is typically performed using variants of stochastic gradient descent, which calculates the gradients of the model's parameters with respect to a loss function.\n",
    "\n",
    "Deep learning has achieved remarkable success in various domains, including computer vision, natural language processing, speech recognition, and robotics. Notable applications include image classification, object detection, machine translation, sentiment analysis, recommendation systems, and autonomous driving.\n",
    "\n",
    "Some popular deep learning architectures include convolutional neural networks (CNNs) for image analysis, recurrent neural networks (RNNs) for sequence data, and transformer models for natural language processing tasks. These architectures, combined with large-scale datasets and powerful hardware, have contributed to significant advancements in artificial intelligence and have revolutionized many industries.\n",
    "\n",
    "\n",
    "### Deep learning terminologies:\n",
    "\n",
    "1. Artificial Neural Network (ANN): A computational model inspired by the structure and function of biological neural networks. ANNs consist of interconnected nodes (artificial neurons) that transmit and process information.\n",
    "\n",
    "2. Deep Neural Network (DNN): A type of artificial neural network with multiple layers between the input and output layers. DNNs are capable of learning complex representations of data.\n",
    "\n",
    "3. Convolutional Neural Network (CNN): A specialized type of deep neural network commonly used for image and video analysis. CNNs utilize convolutional layers to automatically extract spatial hierarchies of features from input data.\n",
    "\n",
    "4. Recurrent Neural Network (RNN): A type of deep neural network that processes sequential data by using feedback connections. RNNs have memory capabilities, enabling them to capture temporal dependencies in the data.\n",
    "\n",
    "5. Long Short-Term Memory (LSTM): A type of recurrent neural network designed to address the vanishing gradient problem. LSTMs have memory cells and gating mechanisms that allow them to capture long-term dependencies in sequential data.\n",
    "\n",
    "6. Generative Adversarial Network (GAN): A framework that consists of two neural networks: a generator network and a discriminator network. GANs are used for generating synthetic data that resembles real data by training the generator to fool the discriminator.\n",
    "\n",
    "7. Autoencoder: A type of neural network used for unsupervised learning and dimensionality reduction. Autoencoders consist of an encoder network that compresses the input data into a latent representation and a decoder network that reconstructs the input data from the latent representation.\n",
    "\n",
    "8. Transfer Learning: A technique in which a pre-trained neural network is used as a starting point for a new task. By leveraging the knowledge learned from a large dataset, transfer learning can accelerate training and improve performance on new, smaller datasets.\n",
    "\n",
    "9. Activation Function: A mathematical function applied to the output of a neuron in a neural network. Activation functions introduce non-linearity, enabling neural networks to model complex relationships in the data. Examples include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
    "\n",
    "10. Loss Function: A function that measures the difference between the predicted output of a neural network and the true output. The loss function guides the optimization process during training, helping the network to adjust its parameters to minimize the error.\n",
    "\n",
    "These are just a few examples of the many terminologies used in the field of deep learning. The field is evolving rapidly, so new terminologies and techniques are constantly emerging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN\n",
    "\n",
    "In the context of deep learning, \"ANN\" typically stands for Artificial Neural Network. Artificial Neural Networks are a fundamental concept in the field of deep learning, inspired by the structure and functioning of biological neural networks in the human brain.\n",
    "\n",
    "Artificial Neural Networks are composed of interconnected artificial neurons or nodes, organized in layers. The layers are usually classified as input, hidden, and output layers. Information flows through the network in a feedforward manner, with the input layer receiving the data, passing it through the hidden layers, and producing an output in the output layer.\n",
    "\n",
    "Each artificial neuron in an ANN performs a weighted sum of its inputs, applies an activation function to the sum, and then passes the result to the next layer. The weights associated with each input are learned during the training process, where the network is trained on labeled data to minimize a specified loss function.\n",
    "\n",
    "Deep learning refers to the use of deep neural networks, which are ANNs with multiple hidden layers. Deep neural networks have shown remarkable success in various tasks such as image recognition, natural language processing, speech recognition, and more.\n",
    "\n",
    "Overall, ANNs play a central role in deep learning, enabling the model to learn complex representations and extract useful features from raw data, leading to powerful predictive and decision-making capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology in ANN\n",
    "\n",
    "Sure! Here are some common terminologies associated with Artificial Neural Networks (ANNs):\n",
    "\n",
    "1. Neuron/Node: It represents a basic processing unit in an ANN, which receives input, performs computations, and produces an output.\n",
    "\n",
    "2. Layer: A layer is a collection of neurons or nodes that process inputs and produce outputs. ANNs typically consist of an input layer, one or more hidden layers, and an output layer.\n",
    "\n",
    "3. Input Layer: The input layer receives input data and passes it to the subsequent layers for processing. It does not perform any computations.\n",
    "\n",
    "4. Hidden Layer: Hidden layers are intermediate layers between the input and output layers. They perform computations on the inputs received from the previous layer.\n",
    "\n",
    "5. Output Layer: The output layer produces the final output or prediction of the neural network. The number of nodes in the output layer depends on the specific task, such as binary classification (1 node) or multi-class classification (multiple nodes).\n",
    "\n",
    "6. Activation Function: An activation function determines the output of a neuron based on its input. Common activation functions include sigmoid, tanh, ReLU (Rectified Linear Unit), and softmax.\n",
    "\n",
    "7. Weight: Each connection between neurons in different layers has an associated weight. The weights represent the strength of the connection and are adjusted during the training process to optimize the network's performance.\n",
    "\n",
    "8. Bias: Bias is an additional parameter in each neuron that helps shift the activation function's output. It allows the network to model more complex relationships between inputs and outputs.\n",
    "\n",
    "9. Forward Propagation: It is the process of passing input data through the network to compute the output. During forward propagation, each neuron performs a weighted sum of its inputs, applies an activation function, and passes the result to the next layer.\n",
    "\n",
    "10. Backpropagation: Backpropagation is a key algorithm for training neural networks. It involves calculating the gradient of the loss function with respect to the weights and biases of the network, and using that information to update the weights and biases in the opposite direction of the gradient.\n",
    "\n",
    "11. Loss Function: The loss function measures the difference between the predicted output and the true output. It quantifies the performance of the network during training and guides the adjustment of the weights and biases.\n",
    "\n",
    "12. Training: Training refers to the process of optimizing the neural network's weights and biases by exposing it to a labeled dataset and adjusting the parameters to minimize the loss function.\n",
    "\n",
    "13. Validation: Validation is a step during training where a separate dataset, not used for training, is used to evaluate the model's performance and tune hyperparameters.\n",
    "\n",
    "14. Test Set: The test set is a dataset that is completely independent of the training and validation sets. It is used to evaluate the final performance of the trained model.\n",
    "\n",
    "These are some of the fundamental terms used in the context of Artificial Neural Networks. Understanding these terminologies will help you grasp the concepts and developments in the field of deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
