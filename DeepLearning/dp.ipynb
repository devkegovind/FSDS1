{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style:align='center'><b>DEEP LEARNING</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is a subfield of machine learning that focuses on training artificial neural networks to learn and make predictions or decisions based on input data. It is inspired by the structure and function of the human brain and is designed to simulate the learning process of neurons.\n",
    "\n",
    "In traditional machine learning approaches, engineers and data scientists manually design features and algorithms to solve specific tasks. However, deep learning automates this feature engineering process by allowing the model to learn hierarchical representations of the data directly from raw input. This is achieved by using artificial neural networks with multiple layers, hence the term \"deep\" learning.\n",
    "\n",
    "Deep learning models are composed of interconnected nodes called artificial neurons or \"units.\" These units are organized into layers, where each layer receives input from the previous layer and passes its output to the next layer. The layers are typically divided into an input layer, one or more hidden layers, and an output layer. The hidden layers are responsible for learning complex representations of the data, while the output layer produces the final prediction or decision.\n",
    "\n",
    "During the training process, deep learning models are exposed to labeled data, and the weights and biases of the connections between units are adjusted iteratively to minimize the difference between the predicted output and the true output. This optimization process is typically performed using variants of stochastic gradient descent, which calculates the gradients of the model's parameters with respect to a loss function.\n",
    "\n",
    "Deep learning has achieved remarkable success in various domains, including computer vision, natural language processing, speech recognition, and robotics. Notable applications include image classification, object detection, machine translation, sentiment analysis, recommendation systems, and autonomous driving.\n",
    "\n",
    "Some popular deep learning architectures include convolutional neural networks (CNNs) for image analysis, recurrent neural networks (RNNs) for sequence data, and transformer models for natural language processing tasks. These architectures, combined with large-scale datasets and powerful hardware, have contributed to significant advancements in artificial intelligence and have revolutionized many industries.\n",
    "\n",
    "\n",
    "### Deep learning terminologies:\n",
    "\n",
    "1. Artificial Neural Network (ANN): A computational model inspired by the structure and function of biological neural networks. ANNs consist of interconnected nodes (artificial neurons) that transmit and process information.\n",
    "\n",
    "2. Deep Neural Network (DNN): A type of artificial neural network with multiple layers between the input and output layers. DNNs are capable of learning complex representations of data.\n",
    "\n",
    "3. Convolutional Neural Network (CNN): A specialized type of deep neural network commonly used for image and video analysis. CNNs utilize convolutional layers to automatically extract spatial hierarchies of features from input data.\n",
    "\n",
    "4. Recurrent Neural Network (RNN): A type of deep neural network that processes sequential data by using feedback connections. RNNs have memory capabilities, enabling them to capture temporal dependencies in the data.\n",
    "\n",
    "5. Long Short-Term Memory (LSTM): A type of recurrent neural network designed to address the vanishing gradient problem. LSTMs have memory cells and gating mechanisms that allow them to capture long-term dependencies in sequential data.\n",
    "\n",
    "6. Generative Adversarial Network (GAN): A framework that consists of two neural networks: a generator network and a discriminator network. GANs are used for generating synthetic data that resembles real data by training the generator to fool the discriminator.\n",
    "\n",
    "7. Autoencoder: A type of neural network used for unsupervised learning and dimensionality reduction. Autoencoders consist of an encoder network that compresses the input data into a latent representation and a decoder network that reconstructs the input data from the latent representation.\n",
    "\n",
    "8. Transfer Learning: A technique in which a pre-trained neural network is used as a starting point for a new task. By leveraging the knowledge learned from a large dataset, transfer learning can accelerate training and improve performance on new, smaller datasets.\n",
    "\n",
    "9. Activation Function: A mathematical function applied to the output of a neuron in a neural network. Activation functions introduce non-linearity, enabling neural networks to model complex relationships in the data. Examples include sigmoid, tanh, and ReLU (Rectified Linear Unit).\n",
    "\n",
    "10. Loss Function: A function that measures the difference between the predicted output of a neural network and the true output. The loss function guides the optimization process during training, helping the network to adjust its parameters to minimize the error.\n",
    "\n",
    "These are just a few examples of the many terminologies used in the field of deep learning. The field is evolving rapidly, so new terminologies and techniques are constantly emerging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
