{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RANDOM FOREST CLASSIFIER**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a popular machine learning algorithm used for classification and regression tasks. It is an ensemble learning method that combines multiple decision trees to make predictions.\n",
    "\n",
    "Here's how the Random Forest classifier works:\n",
    "\n",
    "1. **Data Preparation:** You need to prepare your data by dividing it into a training set and a test set. Each data point should have a set of features (independent variables) and a corresponding target label (dependent variable) for classification.\n",
    "\n",
    "2. **Building Decision Trees:** Random Forest creates an ensemble of decision trees. Each tree is built using a random subset of the training data and a random subset of features. This randomness helps to reduce overfitting and increase the model's generalization ability.\n",
    "\n",
    "3. **Voting for Classification:** During training, each decision tree in the forest independently classifies the input data based on the majority class in its leaf node. The final prediction is determined by taking a majority vote across all the trees in the forest. For example, if there are 100 trees and 70 of them predict class A while 30 predict class B, the Random Forest predicts class A.\n",
    "\n",
    "4. **Handling Overfitting:** Random Forest employs techniques like bootstrapping and feature randomness to address overfitting. Bootstrapping involves sampling the training data with replacement, creating multiple subsets that are used to build different decision trees. Feature randomness involves randomly selecting a subset of features at each node of a decision tree.\n",
    "\n",
    "5. **Prediction:** Once the Random Forest is trained, it can be used to make predictions on new, unseen data. Each decision tree in the forest independently predicts the class label for the input, and the final prediction is determined by majority voting.\n",
    "\n",
    "Random Forest has several advantages, including:\n",
    "\n",
    "- It can handle large datasets with high dimensionality.\n",
    "- It provides good accuracy and generalization ability.\n",
    "- It can handle both numerical and categorical features.\n",
    "- It performs well even with missing data or imbalanced datasets.\n",
    "- It can measure the importance of different features in the classification process.\n",
    "\n",
    "However, Random Forest can be computationally expensive and may not be suitable for real-time applications that require quick predictions.\n",
    "\n",
    "To use Random Forest in Python, you can use libraries like scikit-learn, which provides an implementation of the algorithm. Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = round(rf_classifier.score(X_test, y_test)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we generate a synthetic dataset using `make_classification`, split it into training and test sets, create a Random Forest classifier with 100 trees (`n_estimators=100`), train the classifier, make predictions on the test set, and evaluate the classifier's accuracy.\n",
    "\n",
    "Remember to preprocess your data, handle missing values, and perform feature scaling if necessary before applying the Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
